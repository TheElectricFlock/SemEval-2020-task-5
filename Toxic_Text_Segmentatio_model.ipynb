{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Toxic_Text_Segmentatio_model.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP79GJAw0365QrEWLKMJifk"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"UdpSpxDEdTL1"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SdQ_19h9w70K","executionInfo":{"status":"ok","timestamp":1614114816560,"user_tz":0,"elapsed":39679,"user":{"displayName":"James Bedwell","photoUrl":"","userId":"08359185221310017519"}},"outputId":"f286025e-0f36-420a-c967-327415c4fd60"},"source":["!pip install chars2vec\r\n","import csv\r\n","import chars2vec\r\n","import re\r\n","import numpy as np\r\n","import keras.backend as K\r\n","from tensorflow.keras import datasets, layers, models, losses, callbacks, Model\r\n","import tensorflow as tf\r\n","from sklearn.model_selection import train_test_split\r\n","import statistics\r\n","from google.colab import drive\r\n","\r\n","drive.mount('/content/gdrive')\r\n","root_path = 'gdrive/My Drive/Colab Notebooks/'\r\n","from keras.utils.vis_utils import plot_model\r\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting chars2vec\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/0a/8c327aae23e0532d239ec7b30446aca765eb5d9547b4c4b09cdd82e49797/chars2vec-0.1.7.tar.gz (8.1MB)\n","\u001b[K     |████████████████████████████████| 8.1MB 5.7MB/s \n","\u001b[?25hBuilding wheels for collected packages: chars2vec\n","  Building wheel for chars2vec (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for chars2vec: filename=chars2vec-0.1.7-cp37-none-any.whl size=8111096 sha256=c629a9b705168d016bfb627a770d8d49277f90363c5013aef2fd4bd705e6b9c1\n","  Stored in directory: /root/.cache/pip/wheels/97/b6/65/d7e778ef1213ec77d315aea0f536068b96e36cc94c02abbfde\n","Successfully built chars2vec\n","Installing collected packages: chars2vec\n","Successfully installed chars2vec-0.1.7\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PWm1tEArY6gG"},"source":["def f1(predictions, gold):\r\n","    \"\"\"\r\n","    F1 (a.k.a. DICE) operating on two lists of offsets (e.g., character).\r\n","    >>> assert f1([0, 1, 4, 5], [0, 1, 6]) == 0.5714285714285714\r\n","    :param predictions: a list of predicted offsets\r\n","    :param gold: a list of offsets serving as the ground truth\r\n","    :return: a score between 0 and 1\r\n","    \"\"\"\r\n","    if len(gold) == 0:\r\n","        return 1 if len(predictions) == 0 else 0\r\n","    if len(predictions) == 0:\r\n","        return 0\r\n","    predictions_set = set(predictions)\r\n","    gold_set = set(gold)\r\n","    nom = 2 * len(predictions_set.intersection(gold_set))\r\n","    denom = len(predictions_set) + len(gold_set)\r\n","    return float(nom)/float(denom)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PKEOlxEWy9dz"},"source":["def read_text_data(filename):\r\n","    \"\"\"Reads csv file with python, text.\"\"\"\r\n","    data = []\r\n","    with open(filename) as csvfile:\r\n","        reader = csv.DictReader(csvfile)\r\n","        count = 0\r\n","        for row in reader:\r\n","            data.append(row['text'])\r\n","    csvfile.close()\r\n","    return data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DI0YNeXszIAW"},"source":["def read_data_span(filename):\r\n","    \"\"\"Reads csv file with python, span list.\"\"\"\r\n","    data = []\r\n","    with open(filename) as csvfile:\r\n","        reader = csv.DictReader(csvfile)\r\n","        count = 0\r\n","        for row in reader:\r\n","            data.append(row['span'])\r\n","    csvfile.close()\r\n","    return data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SlbJqSZdzKu7"},"source":["def f1_loss(y_true, y_pred):\r\n","    \r\n","    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\r\n","    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\r\n","    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\r\n","    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\r\n","\r\n","    p = tp / (tp + fp + K.epsilon())\r\n","    r = tp / (tp + fn + K.epsilon())\r\n","\r\n","    f1 = 2*p*r / (p+r+K.epsilon())\r\n","    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\r\n","    return 1 - K.mean(f1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SJyrue9gzNtg","executionInfo":{"status":"ok","timestamp":1614114817551,"user_tz":0,"elapsed":40577,"user":{"displayName":"James Bedwell","photoUrl":"","userId":"08359185221310017519"}},"outputId":"b13d3049-756b-4544-c96a-0c0bbb673d74"},"source":["texts = read_text_data('gdrive/My Drive/Colab Notebooks/Data/tsd_train_readable.csv')\r\n","spans = read_data_span('gdrive/My Drive/Colab Notebooks/Data/tsd_train_readable.csv')\r\n","texts.extend(read_text_data('gdrive/My Drive/Colab Notebooks/Data/tsd_trial_readable.csv'))\r\n","spans.extend(read_data_span('gdrive/My Drive/Colab Notebooks/Data/tsd_trial_readable.csv'))\r\n","\r\n","\r\n","processed_texts = []\r\n","processed_spans = []\r\n","print(f\"Lengths equal: {len(texts)==len(spans)}\" + \"\\n\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Lengths equal: True\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BPLticdKzTQ3"},"source":["# Preprocess data\r\n","c2v_model = chars2vec.load_model('eng_50')\r\n","word_limit = 1000\r\n","for i in range(0, len(texts)-1):\r\n","    to_use = True\r\n","    if len(texts[i]) > word_limit:\r\n","        to_use = False\r\n","    if texts[i] == \"\":\r\n","        to_use = False\r\n","    new_spans = [int(j) for j in spans[i][1:-1].split(\", \")]\r\n","    if max(new_spans) > len(texts[i]) - 1:\r\n","        to_use = False\r\n","    if to_use:\r\n","        if spans[i] != []:\r\n","            full_span = [[0,0,1] for j in range(0, word_limit)]\r\n","            for char_offset in new_spans:\r\n","                full_span[char_offset] = [1,0,0]\r\n","            for j in range(0, len(texts[i])-1):\r\n","                if full_span[j][1] == 0 and full_span[j][2] == 1:\r\n","                    full_span[j] = [0,1,0]\r\n","        else:\r\n","            full_span = [[1,0,0] for j in range(0, len(texts[i]))]           \r\n","        processed_texts.append(texts[i])\r\n","        processed_spans.append(full_span)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sgC4OBpIzWLF"},"source":["# Get the maximim comment size (in no. of chars)\r\n","max_size = 0\r\n","for i in range(0, len(processed_texts)-1):\r\n","    if len(processed_texts[i]) > max_size:\r\n","        max_size = len(processed_texts[i])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mSXC7j5d9yk1","executionInfo":{"status":"ok","timestamp":1614114826714,"user_tz":0,"elapsed":49682,"user":{"displayName":"James Bedwell","photoUrl":"","userId":"08359185221310017519"}},"outputId":"273dea95-6717-49db-8189-d32f9df21791"},"source":["max_size"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1000"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"7ErQHD8LzY1Z"},"source":["# Define the training arrays\r\n","train_Y = np.zeros(shape=(len(processed_spans), max_size, 3))\r\n","train_X = np.zeros(shape=(len(processed_texts), max_size, 50))         "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0nexzfqHyxC9"},"source":["del texts\r\n","del spans"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mlvr4eF9zfTl"},"source":["# Build Train_X\r\n","for x, string in enumerate(processed_texts):\r\n","    for y, char in enumerate(string):\r\n","            char_vect = c2v_model.vectorize_words([char])\r\n","            train_X[x][y] = [word_vect for word_vect in char_vect[0]]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c61dItQbzljv"},"source":["# Build train_Y\r\n","for x, label in enumerate(processed_spans):\r\n","    for y, output in enumerate(label):\r\n","        train_Y[x][y] = output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9U660qMLzz8F"},"source":["# Build test_X, Test_Y\r\n","train_X, test_X, train_Y, test_Y = train_test_split(train_X, train_Y, test_size=0.1, random_state=42)\r\n","class High_Score:\r\n","    def __init__(self):\r\n","        self.high_score = 0\r\n","    def get_high_score(self):\r\n","        return self.high_score\r\n","    def set_high_score(self, new_score):\r\n","        self.high_score = new_score\r\n","high_score = High_Score()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wmw_XiUITJ2d","executionInfo":{"status":"ok","timestamp":1614114893782,"user_tz":0,"elapsed":116636,"user":{"displayName":"James Bedwell","photoUrl":"","userId":"08359185221310017519"}},"outputId":"cace2575-b93b-4beb-f4f6-0f4efa3ba5a8"},"source":["print(train_Y.shape)\r\n","print(train_X.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(7102, 1000, 3)\n","(7102, 1000, 50)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mbvc3atVucHH"},"source":["del processed_texts\r\n","del processed_spans"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tecSwLEfFTez"},"source":[""]},{"cell_type":"code","metadata":{"id":"Lh9DVvyz6NjV"},"source":["class PredictionCallback(callbacks.Callback):    \r\n","    def on_epoch_end(self, epoch, logs={}):\r\n","        y_pred = self.model.predict(test_X)\r\n","        scores = []\r\n","        for x, pred in enumerate(y_pred):\r\n","            score = f1([j for j, i in enumerate(pred) if np.argmax(i) == 0], [j for j, i in enumerate(test_Y[x]) if np.argmax(i) == 0])\r\n","            scores.append(score)\r\n","        score = statistics.mean(scores)\r\n","        if score > high_score.get_high_score():\r\n","            high_score.set_high_score(score)\r\n","            model.save(f\"{root_path}model_autoencoder_LSTM_checkpoint\")\r\n","        print(f\"F1 score: {score}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XE8QY_opI8HD"},"source":["# create architecture\r\n","#model = models.Sequential()\r\n","# vocabulary size — number of unique words in data\r\n","# length of vector with which each word is represented\r\n","#model.add(layers.Input(shape = train_X.shape[1:]))\r\n","# add an LSTM layer which contains 64 LSTM cells\r\n","# True — return whole sequence; False — return single output of the end of the sequence\r\n","#model.add(layers.Dropout(0.3))\r\n","#model.add(layers.GRU(128, return_sequences=True))\r\n","#model.add(layers.RepeatVector(1000))\r\n","#model.add(layers.GRU(256, return_sequences=True))\r\n","#model.add(layers.Dropout(0.3))\r\n","#model.add(layers.TimeDistributed(layers.Dense(3, activation='softmax')))\r\n","#compile model\r\n","#model.compile(loss      =  'categorical_crossentropy',\r\n","#                  optimizer =  'adam',\r\n","#                  metrics   =  ['acc'])\r\n","# check summary of the model\r\n","#model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H3YXwcUTzw6X","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1614130462871,"user_tz":0,"elapsed":13759843,"user":{"displayName":"James Bedwell","photoUrl":"","userId":"08359185221310017519"}},"outputId":"0e155ac1-fd98-431b-9b04-b9e983012148"},"source":["model = models.Sequential()\r\n","model.add(layers.Input(shape = train_X.shape[1:]))\r\n","model.add(layers.Conv1D(filters=32, kernel_size=9, strides=1, padding='same'))\r\n","model.add(layers.BatchNormalization())\r\n","model.add(layers.ELU())\r\n","model.add(layers.Dropout(0.3))\r\n","model.add(layers.MaxPooling1D(strides=2))\r\n","model.add(layers.Conv1D(filters=64, kernel_size=9, strides=1, padding='same'))\r\n","model.add(layers.BatchNormalization())\r\n","model.add(layers.ELU())\r\n","model.add(layers.Dropout(0.3))\r\n","model.add(layers.MaxPooling1D(strides=2))\r\n","model.add(layers.Conv1D(filters=128, kernel_size=9, strides=1, padding='same'))\r\n","model.add(layers.BatchNormalization())\r\n","model.add(layers.ELU())\r\n","model.add(layers.Dropout(0.3))\r\n","model.add(layers.MaxPooling1D(strides=2))\r\n","model.add(layers.Conv1D(filters=256, kernel_size=9, strides=1, padding='same'))\r\n","model.add(layers.BatchNormalization())\r\n","model.add(layers.ELU())\r\n","model.add(layers.Bidirectional(layers.GRU(units=128, return_sequences=True)))\r\n","model.add(layers.BatchNormalization())\r\n","model.add(layers.ELU())\r\n","model.add(layers.Bidirectional(layers.GRU(units=128, return_sequences=True)))\r\n","model.add(layers.BatchNormalization())\r\n","model.add(layers.ELU())\r\n","model.add(layers.Conv1D(filters=256, kernel_size=9, strides=1, padding='same'))\r\n","model.add(layers.BatchNormalization())\r\n","model.add(layers.ELU())\r\n","model.add(layers.Conv1DTranspose(filters=128, kernel_size=9, strides=1, padding='same'))\r\n","model.add(layers.BatchNormalization())\r\n","model.add(layers.ELU())\r\n","model.add(layers.Dropout(0.3))\r\n","model.add(layers.UpSampling1D())\r\n","model.add(layers.Conv1DTranspose(filters=64, kernel_size=9, strides=1, padding='same'))\r\n","model.add(layers.BatchNormalization())\r\n","model.add(layers.ELU())\r\n","model.add(layers.Dropout(0.3))\r\n","model.add(layers.UpSampling1D())\r\n","model.add(layers.Conv1DTranspose(filters=32, kernel_size=9, strides=1, padding='same'))\r\n","model.add(layers.BatchNormalization())\r\n","model.add(layers.ELU())\r\n","model.add(layers.Dropout(0.3))\r\n","model.add(layers.UpSampling1D())\r\n","model.add(layers.Conv1D(filters=3, kernel_size=9, strides=1, padding='same', activation='softmax'))\r\n","model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\r\n","model.summary()\r\n","history = model.fit(train_X, train_Y, epochs=50, batch_size=32, callbacks=[PredictionCallback()])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv1d_18 (Conv1D)           (None, 1000, 32)          14432     \n","_________________________________________________________________\n","batch_normalization_24 (Batc (None, 1000, 32)          128       \n","_________________________________________________________________\n","elu_24 (ELU)                 (None, 1000, 32)          0         \n","_________________________________________________________________\n","dropout_21 (Dropout)         (None, 1000, 32)          0         \n","_________________________________________________________________\n","max_pooling1d_9 (MaxPooling1 (None, 500, 32)           0         \n","_________________________________________________________________\n","conv1d_19 (Conv1D)           (None, 500, 64)           18496     \n","_________________________________________________________________\n","batch_normalization_25 (Batc (None, 500, 64)           256       \n","_________________________________________________________________\n","elu_25 (ELU)                 (None, 500, 64)           0         \n","_________________________________________________________________\n","dropout_22 (Dropout)         (None, 500, 64)           0         \n","_________________________________________________________________\n","max_pooling1d_10 (MaxPooling (None, 250, 64)           0         \n","_________________________________________________________________\n","conv1d_20 (Conv1D)           (None, 250, 128)          73856     \n","_________________________________________________________________\n","batch_normalization_26 (Batc (None, 250, 128)          512       \n","_________________________________________________________________\n","elu_26 (ELU)                 (None, 250, 128)          0         \n","_________________________________________________________________\n","dropout_23 (Dropout)         (None, 250, 128)          0         \n","_________________________________________________________________\n","max_pooling1d_11 (MaxPooling (None, 125, 128)          0         \n","_________________________________________________________________\n","conv1d_21 (Conv1D)           (None, 125, 256)          295168    \n","_________________________________________________________________\n","batch_normalization_27 (Batc (None, 125, 256)          1024      \n","_________________________________________________________________\n","elu_27 (ELU)                 (None, 125, 256)          0         \n","_________________________________________________________________\n","bidirectional_6 (Bidirection (None, 125, 256)          296448    \n","_________________________________________________________________\n","batch_normalization_28 (Batc (None, 125, 256)          1024      \n","_________________________________________________________________\n","elu_28 (ELU)                 (None, 125, 256)          0         \n","_________________________________________________________________\n","bidirectional_7 (Bidirection (None, 125, 256)          296448    \n","_________________________________________________________________\n","batch_normalization_29 (Batc (None, 125, 256)          1024      \n","_________________________________________________________________\n","elu_29 (ELU)                 (None, 125, 256)          0         \n","_________________________________________________________________\n","conv1d_22 (Conv1D)           (None, 125, 256)          590080    \n","_________________________________________________________________\n","batch_normalization_30 (Batc (None, 125, 256)          1024      \n","_________________________________________________________________\n","elu_30 (ELU)                 (None, 125, 256)          0         \n","_________________________________________________________________\n","conv1d_transpose_9 (Conv1DTr (None, 125, 128)          295040    \n","_________________________________________________________________\n","batch_normalization_31 (Batc (None, 125, 128)          512       \n","_________________________________________________________________\n","elu_31 (ELU)                 (None, 125, 128)          0         \n","_________________________________________________________________\n","dropout_24 (Dropout)         (None, 125, 128)          0         \n","_________________________________________________________________\n","up_sampling1d_9 (UpSampling1 (None, 250, 128)          0         \n","_________________________________________________________________\n","conv1d_transpose_10 (Conv1DT (None, 250, 64)           73792     \n","_________________________________________________________________\n","batch_normalization_32 (Batc (None, 250, 64)           256       \n","_________________________________________________________________\n","elu_32 (ELU)                 (None, 250, 64)           0         \n","_________________________________________________________________\n","dropout_25 (Dropout)         (None, 250, 64)           0         \n","_________________________________________________________________\n","up_sampling1d_10 (UpSampling (None, 500, 64)           0         \n","_________________________________________________________________\n","conv1d_transpose_11 (Conv1DT (None, 500, 32)           18464     \n","_________________________________________________________________\n","batch_normalization_33 (Batc (None, 500, 32)           128       \n","_________________________________________________________________\n","elu_33 (ELU)                 (None, 500, 32)           0         \n","_________________________________________________________________\n","dropout_26 (Dropout)         (None, 500, 32)           0         \n","_________________________________________________________________\n","up_sampling1d_11 (UpSampling (None, 1000, 32)          0         \n","_________________________________________________________________\n","conv1d_23 (Conv1D)           (None, 1000, 3)           867       \n","=================================================================\n","Total params: 1,978,979\n","Trainable params: 1,976,035\n","Non-trainable params: 2,944\n","_________________________________________________________________\n","Epoch 1/50\n","222/222 [==============================] - 355s 2s/step - loss: 0.1657 - accuracy: 0.9498\n","F1 score: 0\n","Epoch 2/50\n","222/222 [==============================] - 342s 2s/step - loss: 0.0691 - accuracy: 0.9801\n","F1 score: 0\n","Epoch 3/50\n","222/222 [==============================] - 343s 2s/step - loss: 0.0616 - accuracy: 0.9820\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Found untraced functions such as gru_cell_13_layer_call_fn, gru_cell_13_layer_call_and_return_conditional_losses, gru_cell_14_layer_call_fn, gru_cell_14_layer_call_and_return_conditional_losses, gru_cell_16_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n","WARNING:absl:Found untraced functions such as gru_cell_13_layer_call_fn, gru_cell_13_layer_call_and_return_conditional_losses, gru_cell_14_layer_call_fn, gru_cell_14_layer_call_and_return_conditional_losses, gru_cell_16_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: gdrive/My Drive/Colab Notebooks/model_autoencoder_LSTM_checkpoint/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: gdrive/My Drive/Colab Notebooks/model_autoencoder_LSTM_checkpoint/assets\n"],"name":"stderr"},{"output_type":"stream","text":["F1 score: 0.006034458730994374\n","Epoch 4/50\n","222/222 [==============================] - 343s 2s/step - loss: 0.0642 - accuracy: 0.9807\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Found untraced functions such as gru_cell_13_layer_call_fn, gru_cell_13_layer_call_and_return_conditional_losses, gru_cell_14_layer_call_fn, gru_cell_14_layer_call_and_return_conditional_losses, gru_cell_16_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n","WARNING:absl:Found untraced functions such as gru_cell_13_layer_call_fn, gru_cell_13_layer_call_and_return_conditional_losses, gru_cell_14_layer_call_fn, gru_cell_14_layer_call_and_return_conditional_losses, gru_cell_16_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: gdrive/My Drive/Colab Notebooks/model_autoencoder_LSTM_checkpoint/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: gdrive/My Drive/Colab Notebooks/model_autoencoder_LSTM_checkpoint/assets\n"],"name":"stderr"},{"output_type":"stream","text":["F1 score: 0.009553035793875234\n","Epoch 5/50\n","222/222 [==============================] - 343s 2s/step - loss: 0.0647 - accuracy: 0.9807\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Found untraced functions such as gru_cell_13_layer_call_fn, gru_cell_13_layer_call_and_return_conditional_losses, gru_cell_14_layer_call_fn, gru_cell_14_layer_call_and_return_conditional_losses, gru_cell_16_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n","WARNING:absl:Found untraced functions such as gru_cell_13_layer_call_fn, gru_cell_13_layer_call_and_return_conditional_losses, gru_cell_14_layer_call_fn, gru_cell_14_layer_call_and_return_conditional_losses, gru_cell_16_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: gdrive/My Drive/Colab Notebooks/model_autoencoder_LSTM_checkpoint/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: gdrive/My Drive/Colab Notebooks/model_autoencoder_LSTM_checkpoint/assets\n"],"name":"stderr"},{"output_type":"stream","text":["F1 score: 0.019456867928864433\n","Epoch 6/50\n","222/222 [==============================] - 343s 2s/step - loss: 0.0564 - accuracy: 0.9826\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Found untraced functions such as gru_cell_13_layer_call_fn, gru_cell_13_layer_call_and_return_conditional_losses, gru_cell_14_layer_call_fn, gru_cell_14_layer_call_and_return_conditional_losses, gru_cell_16_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n","WARNING:absl:Found untraced functions such as gru_cell_13_layer_call_fn, gru_cell_13_layer_call_and_return_conditional_losses, gru_cell_14_layer_call_fn, gru_cell_14_layer_call_and_return_conditional_losses, gru_cell_16_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: gdrive/My Drive/Colab Notebooks/model_autoencoder_LSTM_checkpoint/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: gdrive/My Drive/Colab Notebooks/model_autoencoder_LSTM_checkpoint/assets\n"],"name":"stderr"},{"output_type":"stream","text":["F1 score: 0.09873299805105297\n","Epoch 7/50\n","222/222 [==============================] - 342s 2s/step - loss: 0.0574 - accuracy: 0.9823\n","F1 score: 0.08910621200998453\n","Epoch 8/50\n","222/222 [==============================] - 343s 2s/step - loss: 0.0538 - accuracy: 0.9827\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Found untraced functions such as gru_cell_13_layer_call_fn, gru_cell_13_layer_call_and_return_conditional_losses, gru_cell_14_layer_call_fn, gru_cell_14_layer_call_and_return_conditional_losses, gru_cell_16_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n","WARNING:absl:Found untraced functions such as gru_cell_13_layer_call_fn, gru_cell_13_layer_call_and_return_conditional_losses, gru_cell_14_layer_call_fn, gru_cell_14_layer_call_and_return_conditional_losses, gru_cell_16_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: gdrive/My Drive/Colab Notebooks/model_autoencoder_LSTM_checkpoint/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: gdrive/My Drive/Colab Notebooks/model_autoencoder_LSTM_checkpoint/assets\n"],"name":"stderr"},{"output_type":"stream","text":["F1 score: 0.14981685866152983\n","Epoch 9/50\n","222/222 [==============================] - 343s 2s/step - loss: 0.0549 - accuracy: 0.9825\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Found untraced functions such as gru_cell_13_layer_call_fn, gru_cell_13_layer_call_and_return_conditional_losses, gru_cell_14_layer_call_fn, gru_cell_14_layer_call_and_return_conditional_losses, gru_cell_16_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n","WARNING:absl:Found untraced functions such as gru_cell_13_layer_call_fn, gru_cell_13_layer_call_and_return_conditional_losses, gru_cell_14_layer_call_fn, gru_cell_14_layer_call_and_return_conditional_losses, gru_cell_16_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: gdrive/My Drive/Colab Notebooks/model_autoencoder_LSTM_checkpoint/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: gdrive/My Drive/Colab Notebooks/model_autoencoder_LSTM_checkpoint/assets\n"],"name":"stderr"},{"output_type":"stream","text":["F1 score: 0.19539076504520045\n","Epoch 10/50\n","222/222 [==============================] - 344s 2s/step - loss: 0.0547 - accuracy: 0.9822\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Found untraced functions such as gru_cell_13_layer_call_fn, gru_cell_13_layer_call_and_return_conditional_losses, gru_cell_14_layer_call_fn, gru_cell_14_layer_call_and_return_conditional_losses, gru_cell_16_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n","WARNING:absl:Found untraced functions such as gru_cell_13_layer_call_fn, gru_cell_13_layer_call_and_return_conditional_losses, gru_cell_14_layer_call_fn, gru_cell_14_layer_call_and_return_conditional_losses, gru_cell_16_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: gdrive/My Drive/Colab Notebooks/model_autoencoder_LSTM_checkpoint/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: gdrive/My Drive/Colab Notebooks/model_autoencoder_LSTM_checkpoint/assets\n"],"name":"stderr"},{"output_type":"stream","text":["F1 score: 0.3014676041275092\n","Epoch 11/50\n","222/222 [==============================] - 343s 2s/step - loss: 0.0554 - accuracy: 0.9825\n","F1 score: 0.2932663708256974\n","Epoch 12/50\n","222/222 [==============================] - 343s 2s/step - loss: 0.0499 - accuracy: 0.9840\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Found untraced functions such as gru_cell_13_layer_call_fn, gru_cell_13_layer_call_and_return_conditional_losses, gru_cell_14_layer_call_fn, gru_cell_14_layer_call_and_return_conditional_losses, gru_cell_16_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n","WARNING:absl:Found untraced functions such as gru_cell_13_layer_call_fn, gru_cell_13_layer_call_and_return_conditional_losses, gru_cell_14_layer_call_fn, gru_cell_14_layer_call_and_return_conditional_losses, gru_cell_16_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: gdrive/My Drive/Colab Notebooks/model_autoencoder_LSTM_checkpoint/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: gdrive/My Drive/Colab Notebooks/model_autoencoder_LSTM_checkpoint/assets\n"],"name":"stderr"},{"output_type":"stream","text":["F1 score: 0.3188535414981981\n","Epoch 13/50\n","222/222 [==============================] - 343s 2s/step - loss: 0.0509 - accuracy: 0.9837\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Found untraced functions such as gru_cell_13_layer_call_fn, gru_cell_13_layer_call_and_return_conditional_losses, gru_cell_14_layer_call_fn, gru_cell_14_layer_call_and_return_conditional_losses, gru_cell_16_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n","WARNING:absl:Found untraced functions such as gru_cell_13_layer_call_fn, gru_cell_13_layer_call_and_return_conditional_losses, gru_cell_14_layer_call_fn, gru_cell_14_layer_call_and_return_conditional_losses, gru_cell_16_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: gdrive/My Drive/Colab Notebooks/model_autoencoder_LSTM_checkpoint/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: gdrive/My Drive/Colab Notebooks/model_autoencoder_LSTM_checkpoint/assets\n"],"name":"stderr"},{"output_type":"stream","text":["F1 score: 0.38936335029416913\n","Epoch 14/50\n","222/222 [==============================] - 343s 2s/step - loss: 0.0492 - accuracy: 0.9843\n","F1 score: 0.3413555259700044\n","Epoch 15/50\n","222/222 [==============================] - 343s 2s/step - loss: 0.0506 - accuracy: 0.9840\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Found untraced functions such as gru_cell_13_layer_call_fn, gru_cell_13_layer_call_and_return_conditional_losses, gru_cell_14_layer_call_fn, gru_cell_14_layer_call_and_return_conditional_losses, gru_cell_16_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n","WARNING:absl:Found untraced functions such as gru_cell_13_layer_call_fn, gru_cell_13_layer_call_and_return_conditional_losses, gru_cell_14_layer_call_fn, gru_cell_14_layer_call_and_return_conditional_losses, gru_cell_16_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: gdrive/My Drive/Colab Notebooks/model_autoencoder_LSTM_checkpoint/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: gdrive/My Drive/Colab Notebooks/model_autoencoder_LSTM_checkpoint/assets\n"],"name":"stderr"},{"output_type":"stream","text":["F1 score: 0.4293238553532709\n","Epoch 16/50\n","222/222 [==============================] - 344s 2s/step - loss: 0.0517 - accuracy: 0.9836\n","F1 score: 0.2996917584637766\n","Epoch 17/50\n","222/222 [==============================] - 343s 2s/step - loss: 0.0481 - accuracy: 0.9846\n","F1 score: 0.39550156497790884\n","Epoch 18/50\n","222/222 [==============================] - 343s 2s/step - loss: 0.0518 - accuracy: 0.9832\n","F1 score: 0.41654259606516864\n","Epoch 19/50\n","222/222 [==============================] - 343s 2s/step - loss: 0.0492 - accuracy: 0.9844\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Found untraced functions such as gru_cell_13_layer_call_fn, gru_cell_13_layer_call_and_return_conditional_losses, gru_cell_14_layer_call_fn, gru_cell_14_layer_call_and_return_conditional_losses, gru_cell_16_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n","WARNING:absl:Found untraced functions such as gru_cell_13_layer_call_fn, gru_cell_13_layer_call_and_return_conditional_losses, gru_cell_14_layer_call_fn, gru_cell_14_layer_call_and_return_conditional_losses, gru_cell_16_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: gdrive/My Drive/Colab Notebooks/model_autoencoder_LSTM_checkpoint/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: gdrive/My Drive/Colab Notebooks/model_autoencoder_LSTM_checkpoint/assets\n"],"name":"stderr"},{"output_type":"stream","text":["F1 score: 0.4320319610351293\n","Epoch 20/50\n","222/222 [==============================] - 342s 2s/step - loss: 0.0486 - accuracy: 0.9846\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Found untraced functions such as gru_cell_13_layer_call_fn, gru_cell_13_layer_call_and_return_conditional_losses, gru_cell_14_layer_call_fn, gru_cell_14_layer_call_and_return_conditional_losses, gru_cell_16_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n","WARNING:absl:Found untraced functions such as gru_cell_13_layer_call_fn, gru_cell_13_layer_call_and_return_conditional_losses, gru_cell_14_layer_call_fn, gru_cell_14_layer_call_and_return_conditional_losses, gru_cell_16_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: gdrive/My Drive/Colab Notebooks/model_autoencoder_LSTM_checkpoint/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: gdrive/My Drive/Colab Notebooks/model_autoencoder_LSTM_checkpoint/assets\n"],"name":"stderr"},{"output_type":"stream","text":["F1 score: 0.4383081610919049\n","Epoch 21/50\n","222/222 [==============================] - 342s 2s/step - loss: 0.0485 - accuracy: 0.9843\n","F1 score: 0.40163812121458176\n","Epoch 22/50\n","222/222 [==============================] - 342s 2s/step - loss: 0.0474 - accuracy: 0.9845\n","F1 score: 0.3294835535311839\n","Epoch 23/50\n","222/222 [==============================] - 342s 2s/step - loss: 0.0495 - accuracy: 0.9837\n","F1 score: 0.34891268127858543\n","Epoch 24/50\n","222/222 [==============================] - 342s 2s/step - loss: 0.0485 - accuracy: 0.9837\n","F1 score: 0.4295851314628016\n","Epoch 25/50\n","222/222 [==============================] - 342s 2s/step - loss: 0.0466 - accuracy: 0.9841\n","F1 score: 0.39142255614836524\n","Epoch 26/50\n","222/222 [==============================] - 343s 2s/step - loss: 0.0505 - accuracy: 0.9832\n","F1 score: 0.40951163518959793\n","Epoch 27/50\n","222/222 [==============================] - 343s 2s/step - loss: 0.0467 - accuracy: 0.9840\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Found untraced functions such as gru_cell_13_layer_call_fn, gru_cell_13_layer_call_and_return_conditional_losses, gru_cell_14_layer_call_fn, gru_cell_14_layer_call_and_return_conditional_losses, gru_cell_16_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n","WARNING:absl:Found untraced functions such as gru_cell_13_layer_call_fn, gru_cell_13_layer_call_and_return_conditional_losses, gru_cell_14_layer_call_fn, gru_cell_14_layer_call_and_return_conditional_losses, gru_cell_16_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: gdrive/My Drive/Colab Notebooks/model_autoencoder_LSTM_checkpoint/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: gdrive/My Drive/Colab Notebooks/model_autoencoder_LSTM_checkpoint/assets\n"],"name":"stderr"},{"output_type":"stream","text":["F1 score: 0.45637428828421656\n","Epoch 28/50\n","222/222 [==============================] - 344s 2s/step - loss: 0.0486 - accuracy: 0.9835\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Found untraced functions such as gru_cell_13_layer_call_fn, gru_cell_13_layer_call_and_return_conditional_losses, gru_cell_14_layer_call_fn, gru_cell_14_layer_call_and_return_conditional_losses, gru_cell_16_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n","WARNING:absl:Found untraced functions such as gru_cell_13_layer_call_fn, gru_cell_13_layer_call_and_return_conditional_losses, gru_cell_14_layer_call_fn, gru_cell_14_layer_call_and_return_conditional_losses, gru_cell_16_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: gdrive/My Drive/Colab Notebooks/model_autoencoder_LSTM_checkpoint/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: gdrive/My Drive/Colab Notebooks/model_autoencoder_LSTM_checkpoint/assets\n"],"name":"stderr"},{"output_type":"stream","text":["F1 score: 0.46612300881586316\n","Epoch 29/50\n","222/222 [==============================] - 343s 2s/step - loss: 0.0431 - accuracy: 0.9854\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Found untraced functions such as gru_cell_13_layer_call_fn, gru_cell_13_layer_call_and_return_conditional_losses, gru_cell_14_layer_call_fn, gru_cell_14_layer_call_and_return_conditional_losses, gru_cell_16_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n","WARNING:absl:Found untraced functions such as gru_cell_13_layer_call_fn, gru_cell_13_layer_call_and_return_conditional_losses, gru_cell_14_layer_call_fn, gru_cell_14_layer_call_and_return_conditional_losses, gru_cell_16_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: gdrive/My Drive/Colab Notebooks/model_autoencoder_LSTM_checkpoint/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: gdrive/My Drive/Colab Notebooks/model_autoencoder_LSTM_checkpoint/assets\n"],"name":"stderr"},{"output_type":"stream","text":["F1 score: 0.47350949800390874\n","Epoch 30/50\n","222/222 [==============================] - 344s 2s/step - loss: 0.0443 - accuracy: 0.9853\n","F1 score: 0.4142939207510077\n","Epoch 31/50\n","222/222 [==============================] - 343s 2s/step - loss: 0.0449 - accuracy: 0.9848\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Found untraced functions such as gru_cell_13_layer_call_fn, gru_cell_13_layer_call_and_return_conditional_losses, gru_cell_14_layer_call_fn, gru_cell_14_layer_call_and_return_conditional_losses, gru_cell_16_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n","WARNING:absl:Found untraced functions such as gru_cell_13_layer_call_fn, gru_cell_13_layer_call_and_return_conditional_losses, gru_cell_14_layer_call_fn, gru_cell_14_layer_call_and_return_conditional_losses, gru_cell_16_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: gdrive/My Drive/Colab Notebooks/model_autoencoder_LSTM_checkpoint/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: gdrive/My Drive/Colab Notebooks/model_autoencoder_LSTM_checkpoint/assets\n"],"name":"stderr"},{"output_type":"stream","text":["F1 score: 0.5096803665217129\n","Epoch 32/50\n","222/222 [==============================] - 344s 2s/step - loss: 0.0441 - accuracy: 0.9851\n","F1 score: 0.475586323094409\n","Epoch 33/50\n","222/222 [==============================] - 344s 2s/step - loss: 0.0433 - accuracy: 0.9849\n","F1 score: 0.4412608308979224\n","Epoch 34/50\n","222/222 [==============================] - 344s 2s/step - loss: 0.0445 - accuracy: 0.9845\n","F1 score: 0.4751487403661602\n","Epoch 35/50\n","222/222 [==============================] - 344s 2s/step - loss: 0.0435 - accuracy: 0.9851\n","F1 score: 0.45884260042756636\n","Epoch 36/50\n","222/222 [==============================] - 344s 2s/step - loss: 0.0422 - accuracy: 0.9855\n","F1 score: 0.4569140100331053\n","Epoch 37/50\n","222/222 [==============================] - 344s 2s/step - loss: 0.0417 - accuracy: 0.9857\n","F1 score: 0.47104639630220396\n","Epoch 38/50\n"," 67/222 [========>.....................] - ETA: 4:00 - loss: 0.0453 - accuracy: 0.9844"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-8975365c4872>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"categorical_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mPredictionCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"xTw9GNqVPRQC"},"source":[""]},{"cell_type":"code","metadata":{"id":"rACAu8nCZ01L"},"source":["model.save(f\"{root_path}model_autoencoder_LSTM_50_epochs\")\r\n","scores = []\r\n","pred_Y = model.predict(test_X)\r\n","\r\n","for x, pred in enumerate(pred_Y):\r\n","    y_pred_f1_compatible = [j for j, i in enumerate(pred) if np.argmax(i) == 0]\r\n","    y_true_f1_compatible = [j for j, i in enumerate(test_Y[x]) if np.argmax(i) == 0]\r\n","    if test_Y[x] == []:\r\n","        y_pred_f1_compatible = []\r\n","    score = f1(y_pred_f1_compatible, y_true_f1_compatible)\r\n","    scores.append(score)\r\n","\r\n","print('avg F1 %g' % statistics.mean(scores))\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3SgYIaccv1Mj"},"source":["for x, pred in enumerate(pred_Y):\r\n","    score = f1([j for j, i in enumerate(pred) if np.argmax(i) == 0], [j for j, i in enumerate(test_Y[x]) if np.argmax(i) == 0])\r\n","    print(f\"F1 score: {score}\")\r\n","    print(f\"Predicted span one_hot: {[np.argmax(i) for i in pred]}\")\r\n","    print(f\"Predicted span: {[j for j, i in enumerate(pred) if np.argmax(i) == 0]}\")\r\n","    print(f\"Ground truth span: {[j for j, i in enumerate(test_Y[x]) if np.argmax(i) == 0]}\" + \"\\n\")\r\n","    if x == 100:\r\n","      break\r\n","    "],"execution_count":null,"outputs":[]}]}